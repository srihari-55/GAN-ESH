{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up some parameters\n",
    "\n",
    "# Root directory for dataset\n",
    "\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 128\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of generator channels\n",
    "ngc = 4\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparameter for Adam optimizers\n",
    "beta1 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StegEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StegEncoder, self).__init__()\n",
    "\n",
    "        #cover image\n",
    "        self.cover = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ngc, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # state size. (ngc) x 32 x 32\n",
    "            nn.Conv2d(ngc, ngc * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngc * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # state size. (ngc*2) x 16 x 16\n",
    "            nn.Conv2d(ngc * 2, ngc * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngc * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # state size. (ngc*4) x 8 x 8\n",
    "            nn.Conv2d(ngc * 4, ngc * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngc * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            #state size. (ngc*8) x 4 x 4\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(ngc*8*4*4, nz),\n",
    "        )\n",
    "\n",
    "        #secret image\n",
    "        self.secret = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ngc, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # state size. (ngc) x 32 x 32\n",
    "            nn.Conv2d(ngc, ngc * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngc * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # state size. (ngc*2) x 16 x 16\n",
    "            nn.Conv2d(ngc * 2, ngc * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngc * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # state size. (ngc*4) x 8 x 8\n",
    "            nn.Conv2d(ngc * 4, ngc * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngc * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            #state size. (ngc*8) x 4 x 4\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(ngc*8*4*4, nz),\n",
    "        )\n",
    "\n",
    "        #generator for stego image\n",
    "        self.stego = nn.Sequential(\n",
    "            # input is 2*nz (latent vectors of cover and secret images concatenated)\n",
    "            nn.ConvTranspose2d(2*nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, secret, cover):\n",
    "        cover = self.cover(cover)\n",
    "        secret = self.secret(secret)\n",
    "        stego = torch.cat((cover, secret), 1)\n",
    "        stego = stego.view(-1, 2*nz, 1, 1)\n",
    "        stego = self.stego(stego)\n",
    "        return stego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StegDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StegDecoder, self).__init__()\n",
    "\n",
    "        self.reverseStego = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ngc, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # state size. (ngc) x 32 x 32\n",
    "            nn.Conv2d(ngc, ngc * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngc * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # state size. (ngc*2) x 16 x 16\n",
    "            nn.Conv2d(ngc * 2, ngc * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngc * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # state size. (ngc*4) x 8 x 8\n",
    "            nn.Conv2d(ngc * 4, ngc * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngc * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            #state size. (ngc*8) x 4 x 4\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(ngc*8*4*4, nz),\n",
    "        )\n",
    "\n",
    "        self.regenerate = nn.Sequential(\n",
    "            # input is (nz) x 1 x 1\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, stego):\n",
    "        stego = self.reverseStego(stego)\n",
    "        stego = stego.view(-1, nz, 1, 1)\n",
    "        stego = self.regenerate(stego)\n",
    "        return stego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.compress = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ngc, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # state size. (ngc) x 32 x 32\n",
    "            nn.Conv2d(ngc, ngc * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngc * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # state size. (ngc*2) x 16 x 16\n",
    "            nn.Conv2d(ngc * 2, ngc * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngc * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # state size. (ngc*4) x 8 x 8\n",
    "            nn.Conv2d(ngc * 4, ngc * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngc * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            #state size. (ngc*8) x 4 x 4\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(ngc*8*4*4, nz),\n",
    "        )\n",
    "\n",
    "        self.classify = nn.Sequential(\n",
    "            nn.Linear(nz, nz / 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(nz / 4, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        image = self.compress(image)\n",
    "        image = self.classify(image)\n",
    "        return image\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss functions\n",
    "\n",
    "a = 1\n",
    "b = 1\n",
    "\n",
    "class CoverMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CoverMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, cover, stego):\n",
    "        return torch.mean((cover - stego) ** 2)\n",
    "    \n",
    "class SecretMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SecretMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, secret, stego):\n",
    "        return torch.mean((secret - stego) ** 2)\n",
    "    \n",
    "class EncDecLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncDecLoss, self).__init__()\n",
    "\n",
    "    def forward(self, cover, secret, stego, stego_decoded):\n",
    "        return a * CoverMSELoss(cover, stego) + b * SecretMSELoss(secret, stego_decoded)\n",
    "    \n",
    "encDecCriterion = EncDecLoss()\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(img_dataloader, enc, dec, disc, encDecOptim, discOptim, encDecCriterion, criterion, num_epochs, mix_coeff):\n",
    "    #update discriminator 4 times for every generator training\n",
    "\n",
    "    #put in training mode\n",
    "    enc.train()\n",
    "    dec.train()\n",
    "    disc.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, data in enumerate(img_dataloader, 0):\n",
    "            if i % 5 == 0:\n",
    "                #update generator\n",
    "                encDecOptim.zero_grad()\n",
    "                cover, secret = data\n",
    "                cover = cover.to(device)\n",
    "                secret = secret.to(device)\n",
    "                stego = enc(secret, cover)\n",
    "                stego_decoded = dec(stego)\n",
    "                gen_loss = disc(stego)\n",
    "                loss = encDecCriterion(cover, secret, stego, stego_decoded) + mix_coeff * gen_loss\n",
    "                loss.backward()\n",
    "                encDecOptim.step()\n",
    "            else:\n",
    "                #update discriminator\n",
    "                discOptim.zero_grad()\n",
    "                cover, secret = data\n",
    "                cover = cover.to(device)\n",
    "                secret = secret.to(device)\n",
    "                stego = enc(secret, cover)\n",
    "                real = torch.zeros((batch_size, 1), device=device)\n",
    "                fake = torch.ones((batch_size, 1), device=device)\n",
    "                real_loss = criterion(disc(cover), real)\n",
    "                fake_loss = criterion(disc(stego), fake)\n",
    "                loss = real_loss + fake_loss\n",
    "                loss.backward()\n",
    "                discOptim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#Dataset,  dataloader (cover, secret ---> the return format of the dataloader)\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, transform=None):\n",
    "        self.images = images\n",
    "        self.pairs = []\n",
    "        self.createPairs()\n",
    "        self.transform = transform\n",
    "    \n",
    "    def createPairs(self):\n",
    "        #create pairs of images for cover and secret\n",
    "        for i in range(len(self.images)):\n",
    "            for j in range(len(self.images)):\n",
    "                self.pairs.append((self.images[i], self.images[j]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        cover = self.images[self.pairs[idx][0]]\n",
    "        secret = self.images[self.pairs[idx][1]]\n",
    "        self.transform(cover)\n",
    "        self.transform(secret)\n",
    "        return cover, secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    # transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "img_dir = \"path/to/directory\"\n",
    "\n",
    "images = [Image.open(img_dir + img) for img in os.listdir(img_dir)]\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(Dataset(images), batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "enc = StegEncoder().to(device)\n",
    "dec = StegDecoder().to(device)\n",
    "disc = Discriminator().to(device)\n",
    "\n",
    "encDecOptim = torch.optim.Adam(enc.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "discOptim = torch.optim.Adam(disc.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "enc.apply(weights_init)\n",
    "dec.apply(weights_init)\n",
    "disc.apply(weights_init)\n",
    "\n",
    "train(train_dataloader, enc, dec, disc, encDecOptim, discOptim, encDecCriterion, criterion, num_epochs, 0.5)\n",
    "\n",
    "#save the model\n",
    "torch.save(enc.state_dict(), \"encoder.pth\")\n",
    "torch.save(dec.state_dict(), \"decoder.pth\")\n",
    "torch.save(disc.state_dict(), \"discriminator.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
